{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import ast\n",
    "from paragraph import extract_paragraphs_from_docx\n",
    "import os\n",
    "\n",
    "def get_response_gpt4(content):\n",
    "    \"\"\" 获取gpt-4模型的回复\n",
    "\n",
    "    Args:\n",
    "        content (_type_): 给gpt-4的问题\n",
    "\n",
    "    Returns:\n",
    "        _type_: 模型的回答\n",
    "    \"\"\"\n",
    "    url = \"https://gateway.ai.cloudflare.com/v1/05c43e30f91a115d8153715954fd70ee/lingyue-ai/openai/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer 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\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"gpt-4-0613\",\n",
    "        \n",
    "        \"messages\": [\n",
    "            {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"{content}\"\n",
    "            }\n",
    "        ],\n",
    "        }\n",
    "        \n",
    "\n",
    "    response = requests.post(url, json=data, headers=headers)\n",
    "\n",
    "    # 假设 response.text 是一个字符串，内容是有效的JSON\n",
    "    json_string = response.text\n",
    "    # 将JSON字符串转换为字典\n",
    "    data_json = json.loads(json_string)\n",
    "    return data_json[\"choices\"][0][\"message\"][\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_ques_list(paragraphs):\n",
    "    \"\"\"输入段落返回提取的实体、相关句子和提问问题\n",
    "\n",
    "    Args:\n",
    "        paragraphs (_type_): 段落\n",
    "\n",
    "    Returns:\n",
    "        _type_: 实体、相关句子和提问问题组成的json\n",
    "    \"\"\"\n",
    "    json_string = get_response_gpt4(f\"{paragraphs} \\n 请根据我给出的上述段落，提取出其中的实体（识别和分类文本中的组织、个人、行业、地点、时间、数值、货币、交易、证券、法律等关键信息）和提到实体的相关语句,实体的提取尽量细致一些，实体尽可能多一些，假设只知道段落主题而并不知道段落内容，而是通过问题引导来完成段落的写作，给出得到相关语句可能会问到的问题，使得问题能够引导出相关句子，问题不要包含具体时间，年份，问题不应出现倾向和定性说法，问题可以包含具体地点和行业，主要体现作者的思路和逻辑，并以json的形式返回[{{{{{{'entity': '','sentence': '', 'question': ''}}}}, {{{{'entity': '','sentence': '', 'question': ''}}}}}}],除了这个json信息其余的不要返回。\")\n",
    "    actual_list = ast.literal_eval(json_string)\n",
    "    return actual_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_questions(data_dict, question_list):\n",
    "    \"\"\"整合entity层级和对应question的函数\n",
    "\n",
    "    Args:\n",
    "        data_dict (_type_): entity层级数据\n",
    "        question_list (_type_): entity对应question的json数据\n",
    "    \"\"\"\n",
    "    # 如果存在 'subentity'，临时移除\n",
    "    subentities = data_dict.pop('subentity', None)\n",
    "    # 通过entity值在question_list中查找匹配的question，并更新data_dict\n",
    "    if 'entity' in data_dict:\n",
    "        entity = data_dict['entity']\n",
    "        # 在列表中查找对应的entity，并更新question\n",
    "        for item in question_list:\n",
    "            if item['entity'] == entity:\n",
    "                data_dict['question'] = item['question']\n",
    "                data_dict['sentence'] = item['sentence']\n",
    "                break  # 找到匹配后即退出循环\n",
    "\n",
    "    # 如果有 'subentity' 属性，递归处理每个子字典\n",
    "    if 'subentity' in data_dict:\n",
    "        for sub in data_dict['subentity']:\n",
    "            update_questions(sub, question_list)\n",
    "    # 在其他更新完成后，如果存在，将 'subentity' 添加回data_dict\n",
    "    if subentities:\n",
    "        data_dict['subentity'] = subentities\n",
    "        # 递归处理每个子字典\n",
    "        for sub in data_dict['subentity']:\n",
    "            update_questions(sub, question_list)\n",
    "    else:\n",
    "        data_dict['subentity'] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在创建 Document 对象...\n",
      "Document 对象创建成功\n",
      "正在提取段落...\n",
      "文件已成功转换并保存至: /home/luzhenye/PythonProject/gpt/（可公开）次高端白酒行业深度报告：势能向上，成长可期.txt\n",
      "总共提取出 52 个段落\n",
      "段落3发生错误：invalid character '，' (U+FF0C) (<unknown>, line 20)\n",
      "段落24发生错误：'str' object has no attribute 'pop'\n",
      "段落30发生错误：'str' object has no attribute 'pop'\n",
      "段落39发生错误：'str' object has no attribute 'pop'\n",
      "段落43发生错误：invalid character '，' (U+FF0C) (<unknown>, line 24)\n",
      "段落48发生错误：invalid character '：' (U+FF1A) (<unknown>, line 1)\n",
      "段落49发生错误：'str' object has no attribute 'pop'\n"
     ]
    }
   ],
   "source": [
    "def get_entity_list_from_docx(input_file,output_json=None):\n",
    "    extract_paragraphs_from_docx(input_file)\n",
    "    # 获取文件名和文件夹路径\n",
    "    file_name = os.path.basename(input_file)\n",
    "    output_folder = os.path.dirname(input_file)\n",
    "    # 构建输出文件路径\n",
    "    output_file = os.path.join(output_folder, os.path.splitext(file_name)[0] + \".txt\")\n",
    "    with open(output_file,\"r\",encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "    paragraphs = text.split(\"段落：\")\n",
    "    paragraphs = [item for item in paragraphs if item != \"\"]\n",
    "    result = []\n",
    "    max_attempts = 3\n",
    "    for index,paragraph in enumerate(paragraphs):\n",
    "        attempts = 0\n",
    "        while attempts < max_attempts:\n",
    "            try :\n",
    "                sub_result = {\"paragraph\":paragraph,\"entities\":[]}\n",
    "                actual_list = get_entity_ques_list(paragraph)\n",
    "                entity_list = [item[\"entity\"] for item in actual_list]\n",
    "                # 获取实体层级\n",
    "                entity_str = get_response_gpt4(f\"{entity_list} \\n 根据以上我给的实体列表根据其含义和逻辑上的层级，给出一个树状的数据结构[{{entity:'',subentity:[]}}],只返回这个json数据，不要返回别的信息\")\n",
    "                # 使用literal_eval来转换字符串到列表\n",
    "                sub_result[\"entities\"] = ast.literal_eval(entity_str)\n",
    "                for data_dict in sub_result[\"entities\"]:\n",
    "                    update_questions(data_dict,actual_list)\n",
    "                result.append(sub_result)\n",
    "                break  # 成功后退出循环\n",
    "            except Exception as e:\n",
    "                attempts += 1\n",
    "                # 记录错误信息和发生错误时的i值\n",
    "                print(f\"段落{index}发生错误：{e}\")\n",
    "                continue  # 自动跳到下一个循环迭代\n",
    "    if output_json == None:\n",
    "        with open(os.path.join(output_folder, os.path.splitext(file_name)[0] + \".json\"), 'w',encoding=\"utf-8\") as file:\n",
    "            json.dump(result, file,ensure_ascii=False, indent=4)\n",
    "    else:\n",
    "        with open(output_json, 'w',encoding=\"utf-8\") as file:\n",
    "            json.dump(result, file,ensure_ascii=False, indent=4)\n",
    "get_entity_list_from_docx(\"/home/luzhenye/PythonProject/gpt/（可公开）次高端白酒行业深度报告：势能向上，成长可期.docx\")\n",
    "erro = [6,12,22,36]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
